# ğŸš€ AIè¯­éŸ³æ”¿æ²»é£é™©ç›‘æ§ç³»ç»Ÿ - æ€§èƒ½ä¼˜åŒ–é…ç½®
# é«˜çº§æ€§èƒ½è°ƒä¼˜å’Œèµ„æºç®¡ç†

performance:
  # ğŸ¤– AIæ¨¡å‹ä¼˜åŒ–
  model_optimization:
    # GPUåŠ é€Ÿé…ç½®
    gpu:
      enabled: true
      device_ids: [0, 1]  # æ”¯æŒå¤šGPU
      memory_fraction: 0.8  # GPUå†…å­˜ä½¿ç”¨æ¯”ä¾‹
      allow_growth: true  # åŠ¨æ€å†…å­˜åˆ†é…
      mixed_precision: true  # æ··åˆç²¾åº¦è®­ç»ƒ
      
      # CUDAä¼˜åŒ–
      cuda:
        benchmark: true  # å¯ç”¨cuDNNåŸºå‡†æµ‹è¯•
        deterministic: false  # æ€§èƒ½ä¼˜å…ˆï¼Œä¸ä¿è¯ç¡®å®šæ€§
        empty_cache_threshold: 0.5  # å†…å­˜æ¸…ç†é˜ˆå€¼
    
    # æ¨¡å‹é‡åŒ–
    quantization:
      enabled: true
      method: "dynamic"  # dynamic, static, qat
      backend: "fbgemm"  # fbgemm, qnnpack
      dtype: "qint8"
      calibration_batches: 100
    
    # æ¨¡å‹å¹¶è¡Œ
    parallelism:
      data_parallel: true
      model_parallel: false
      pipeline_parallel: false
      gradient_checkpointing: true
    
    # æ¨ç†ä¼˜åŒ–
    inference:
      batch_size: 4
      max_sequence_length: 2048
      beam_search_size: 5
      temperature: 0.7
      top_p: 0.9
      num_return_sequences: 1
      
      # TensorRTä¼˜åŒ– (NVIDIA GPU)
      tensorrt:
        enabled: false
        precision: "fp16"
        max_workspace_size: 2147483648  # 2GB
        
      # ONNXä¼˜åŒ–
      onnx:
        enabled: false
        optimization_level: "all"
        providers: ["CUDAExecutionProvider", "CPUExecutionProvider"]

  # ğŸ”„ å¼‚æ­¥å¤„ç†ä¼˜åŒ–
  async_processing:
    # çº¿ç¨‹æ± é…ç½®
    thread_pool:
      max_workers: 8
      thread_name_prefix: "audio-ai-worker"
      
    # è¿›ç¨‹æ± é…ç½®  
    process_pool:
      max_workers: 4
      maxtasksperchild: 100
      
    # åç¨‹ä¼˜åŒ–
    asyncio:
      event_loop_policy: "uvloop"  # é«˜æ€§èƒ½äº‹ä»¶å¾ªç¯
      max_concurrent_tasks: 100
      task_timeout_seconds: 300
      
    # é˜Ÿåˆ—é…ç½®
    queue:
      maxsize: 1000
      redis_queue:
        max_connections: 20
        connection_pool_kwargs:
          max_connections: 50
          retry_on_timeout: true

  # ğŸ—„ï¸ æ•°æ®åº“ä¼˜åŒ–
  database:
    # MongoDBä¼˜åŒ–
    mongodb:
      # è¿æ¥æ± 
      connection_pool:
        min_pool_size: 5
        max_pool_size: 50
        max_idle_time_ms: 30000
        
      # è¯»å†™åˆ†ç¦»
      read_preference: "secondaryPreferred"
      write_concern:
        w: 1
        j: true
        wtimeout: 10000
        
      # ç´¢å¼•ä¼˜åŒ–
      indexes:
        background_building: true
        sparse_indexes: true
        compound_indexes: true
        
      # èšåˆä¼˜åŒ–
      aggregation:
        allow_disk_use: true
        cursor_batch_size: 1000
        max_time_ms: 30000
    
    # Redisä¼˜åŒ–
    redis:
      # è¿æ¥æ± 
      connection_pool:
        max_connections: 50
        retry_on_timeout: true
        health_check_interval: 30
        
      # å†…å­˜ä¼˜åŒ–
      memory:
        maxmemory_policy: "allkeys-lru"
        maxmemory: "512mb"
        
      # æŒä¹…åŒ–é…ç½®
      persistence:
        save_intervals: ["900 1", "300 10", "60 10000"]
        appendonly: true
        appendfsync: "everysec"

  # ğŸŒ ç½‘ç»œä¼˜åŒ–
  networking:
    # HTTP/HTTPSä¼˜åŒ–
    http:
      keep_alive: true
      keep_alive_timeout: 65
      max_keep_alive_requests: 1000
      
      # å‹ç¼©é…ç½®
      compression:
        enabled: true
        level: 6
        min_size: 1024
        types: ["text/plain", "application/json", "text/html"]
      
      # ç¼“å­˜é…ç½®
      caching:
        static_files_cache_age: 86400  # 1å¤©
        api_cache_age: 300  # 5åˆ†é’Ÿ
        browser_cache: true
    
    # TCPä¼˜åŒ–
    tcp:
      nodelay: true
      keepalive: true
      keepalive_idle: 600
      keepalive_interval: 60
      keepalive_count: 3
      
    # è´Ÿè½½å‡è¡¡
    load_balancing:
      algorithm: "round_robin"  # round_robin, least_conn, ip_hash
      health_check_interval: 30
      fail_timeout: 30
      max_fails: 3

  # ğŸ’¾ å†…å­˜ç®¡ç†
  memory:
    # Pythonå†…å­˜ä¼˜åŒ–
    python:
      garbage_collection:
        enabled: true
        generation_thresholds: [700, 10, 10]
        debug: false
        
      # å¯¹è±¡æ± 
      object_pooling:
        enabled: true
        max_pool_size: 1000
        cleanup_interval: 300
        
    # ç¼“å­˜ç­–ç•¥
    caching:
      # åº”ç”¨çº§ç¼“å­˜
      application:
        max_size: 1000
        ttl_seconds: 3600
        eviction_policy: "lru"
        
      # æ¨¡å‹ç¼“å­˜
      model:
        enabled: true
        max_models: 3
        unload_timeout: 1800  # 30åˆ†é’Ÿ
        
      # æ–‡ä»¶ç¼“å­˜
      file:
        enabled: true
        max_size_mb: 1024
        cleanup_age_hours: 24

  # ğŸ“Š I/Oä¼˜åŒ–
  io:
    # æ–‡ä»¶I/O
    file_io:
      buffer_size: 65536  # 64KB
      use_sendfile: true
      direct_io: false
      
      # å¼‚æ­¥æ–‡ä»¶æ“ä½œ
      async_file_ops: true
      max_concurrent_uploads: 10
      
    # ç£ç›˜ä¼˜åŒ–
    disk:
      # SSDä¼˜åŒ–
      ssd_optimized: true
      trim_enabled: true
      
      # æ–‡ä»¶ç³»ç»Ÿ
      filesystem: "ext4"  # ext4, xfs, btrfs
      mount_options: "noatime,nodiratime"
      
    # ç½‘ç»œI/O
    network_io:
      socket_buffer_size: 262144  # 256KB
      tcp_window_scaling: true
      tcp_timestamps: true

  # ğŸ”§ ç³»ç»Ÿçº§ä¼˜åŒ–
  system:
    # CPUä¼˜åŒ–
    cpu:
      # CPUäº²å’Œæ€§
      affinity:
        enabled: true
        worker_cpu_binding: true
        isolation_cpus: []
        
      # è°ƒåº¦å™¨
      scheduler:
        policy: "SCHED_NORMAL"
        nice_level: 0
        rt_priority: 0
        
      # é¢‘ç‡è°ƒèŠ‚
      governor: "performance"  # performance, powersave, ondemand
      
    # å†…æ ¸å‚æ•°ä¼˜åŒ–
    kernel:
      # ç½‘ç»œå‚æ•°
      net:
        core_rmem_max: 134217728
        core_wmem_max: 134217728
        ipv4_tcp_rmem: "4096 87380 134217728"
        ipv4_tcp_wmem: "4096 65536 134217728"
        ipv4_tcp_congestion_control: "bbr"
        
      # è™šæ‹Ÿå†…å­˜
      vm:
        swappiness: 10
        dirty_ratio: 15
        dirty_background_ratio: 5
        vfs_cache_pressure: 50
        
      # æ–‡ä»¶æè¿°ç¬¦
      fs:
        file_max: 1048576
        inotify_max_user_watches: 524288

  # ğŸ“ˆ ç›‘æ§å’Œåˆ†æ
  monitoring:
    # æ€§èƒ½æŒ‡æ ‡æ”¶é›†
    metrics:
      enabled: true
      collection_interval: 10  # ç§’
      retention_days: 30
      
      # å…³é”®æŒ‡æ ‡
      key_metrics:
        - "cpu_usage"
        - "memory_usage"
        - "gpu_usage"
        - "disk_io"
        - "network_io"
        - "request_latency"
        - "queue_size"
        - "error_rate"
        
    # æ€§èƒ½åˆ†æ
    profiling:
      enabled: false  # ç”Ÿäº§ç¯å¢ƒé€šå¸¸å…³é—­
      profiler: "py-spy"  # py-spy, cProfile, line_profiler
      sampling_rate: 100  # Hz
      duration_seconds: 60
      
    # è‡ªåŠ¨è°ƒä¼˜
    auto_tuning:
      enabled: true
      adaptation_interval: 3600  # 1å°æ—¶
      min_adjustment_threshold: 0.1
      max_adjustment_factor: 1.5

# ğŸ¯ ç¯å¢ƒç‰¹å®šé…ç½®
environments:
  development:
    debug_mode: true
    hot_reload: true
    detailed_logging: true
    performance_monitoring: false
    
  testing:
    debug_mode: false
    mock_external_services: true
    performance_monitoring: true
    load_testing: true
    
  production:
    debug_mode: false
    optimize_for_latency: true
    optimize_for_throughput: true
    performance_monitoring: true
    auto_scaling: true

# ğŸš€ è‡ªåŠ¨ä¼˜åŒ–é…ç½®
auto_optimization:
  # è‡ªé€‚åº”æ‰¹å¤„ç†
  adaptive_batching:
    enabled: true
    min_batch_size: 1
    max_batch_size: 16
    target_latency_ms: 2000
    
  # åŠ¨æ€èµ„æºåˆ†é…
  dynamic_scaling:
    enabled: true
    metrics: ["cpu_usage", "memory_usage", "queue_size"]
    scale_up_threshold: 0.8
    scale_down_threshold: 0.3
    cooldown_period: 300  # 5åˆ†é’Ÿ
    
  # æ™ºèƒ½ç¼“å­˜
  intelligent_caching:
    enabled: true
    cache_hit_ratio_target: 0.8
    auto_eviction: true
    predictive_preloading: true
