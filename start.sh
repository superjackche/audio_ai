#!/bin/bash

# ğŸš€ AIè¯­éŸ³æ”¿æ²»é£é™©ç›‘æ§ç³»ç»Ÿ - ç”Ÿäº§å¯åŠ¨è„šæœ¬
# =============================================

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# ASCIIè‰ºæœ¯
echo -e "${PURPLE}"
cat << "EOF"
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                               â•‘
    â•‘    ğŸš€ AIè¯­éŸ³æ”¿æ²»é£é™©ç›‘æ§ç³»ç»Ÿ - ç”Ÿäº§å¯åŠ¨å™¨                    â•‘
    â•‘                                                               â•‘
    â•‘    âš¡ è‡ªåŠ¨ä¼˜åŒ–é…ç½® | ğŸ¯ æœ€å¤§åŒ–æ€§èƒ½ | ğŸ”§ æ™ºèƒ½è°ƒä¼˜            â•‘
    â•‘                                                               â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EOF
echo -e "${NC}"

# å‡½æ•°ï¼šæ‰“å°å½©è‰²æ¶ˆæ¯
print_status() {
    echo -e "${GREEN}[âœ…]${NC} $1"
}

print_info() {
    echo -e "${BLUE}[â„¹ï¸ ]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[âš ï¸ ]${NC} $1"
}

print_error() {
    echo -e "${RED}[âŒ]${NC} $1"
    exit 1
}

print_progress() {
    echo -e "${CYAN}[ğŸ”„]${NC} $1"
}

# æ£€æŸ¥Pythonç¯å¢ƒ
check_python_env() {
    print_progress "æ£€æŸ¥Pythonç¯å¢ƒ..."
    
    if ! command -v python &> /dev/null; then
        print_error "Pythonæœªå®‰è£…æˆ–ä¸åœ¨PATHä¸­"
    fi
    
    PYTHON_VERSION=$(python --version 2>&1 | awk '{print $2}')
    print_info "Pythonç‰ˆæœ¬: $PYTHON_VERSION"
    
    # æ£€æŸ¥condaç¯å¢ƒ
    if [[ "$CONDA_DEFAULT_ENV" == "audio_ai" ]]; then
        print_status "å·²åœ¨audio_ai condaç¯å¢ƒä¸­"
    else
        print_warning "æœªåœ¨audio_aiç¯å¢ƒä¸­ï¼Œå°è¯•æ¿€æ´»..."
        if command -v conda &> /dev/null; then
            source "$(conda info --base)/etc/profile.d/conda.sh"
            conda activate audio_ai
            print_status "å·²æ¿€æ´»audio_aiç¯å¢ƒ"
        else
            print_warning "Condaæœªæ‰¾åˆ°ï¼Œç»§ç»­ä½¿ç”¨å½“å‰Pythonç¯å¢ƒ"
        fi
    fi
}

# æ£€æŸ¥ä¾èµ–åŒ…
check_dependencies() {
    print_progress "æ£€æŸ¥æ ¸å¿ƒä¾èµ–åŒ…..."
    
    REQUIRED_PACKAGES=(
        "torch"
        "transformers"
        "fastapi"
        "uvicorn"
        "numpy"
        "psutil"
        "GPUtil"
    )
    
    MISSING_PACKAGES=()
    
    for package in "${REQUIRED_PACKAGES[@]}"; do
        if python -c "import $package" &> /dev/null; then
            print_status "$package âœ“"
        else
            print_warning "$package âœ— (ç¼ºå¤±)"
            MISSING_PACKAGES+=("$package")
        fi
    done
    
    if [ ${#MISSING_PACKAGES[@]} -gt 0 ]; then
        print_error "ç¼ºå°‘å¿…è¦ä¾èµ–åŒ…: ${MISSING_PACKAGES[*]}. è¯·è¿è¡Œ: pip install -r requirements.txt"
    fi
}

# æ£€æŸ¥GPUç¯å¢ƒ
check_gpu() {
    print_progress "æ£€æŸ¥GPUç¯å¢ƒ..."
    
    if command -v nvidia-smi &> /dev/null; then
        GPU_COUNT=$(nvidia-smi --list-gpus | wc -l)
        print_status "æ£€æµ‹åˆ° $GPU_COUNT ä¸ªGPUè®¾å¤‡"
        nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits | while read line; do
            print_info "GPU: $line"
        done
    else
        print_warning "æœªæ£€æµ‹åˆ°NVIDIA GPUæˆ–nvidia-smiæœªå®‰è£…"
    fi
    
    # æ£€æŸ¥PyTorch CUDAæ”¯æŒ
    if python -c "import torch; print(f'PyTorch CUDA: {torch.cuda.is_available()}')" 2>/dev/null; then
        print_status "PyTorch CUDAæ”¯æŒå·²å¯ç”¨"
    else
        print_warning "PyTorch CUDAæ”¯æŒæœªå¯ç”¨"
    fi
}

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
check_models() {
    print_progress "æ£€æŸ¥æ¨¡å‹æ–‡ä»¶..."
    
    # æ£€æŸ¥Whisperæ¨¡å‹ç¼“å­˜
    WHISPER_CACHE="./models/cache/models--openai--whisper-large-v3"
    if [[ -d "$WHISPER_CACHE" ]] && [[ -f "$WHISPER_CACHE/snapshots"*"/pytorch_model.bin" || -f "$WHISPER_CACHE/snapshots"*"/model.safetensors" ]]; then
        print_status "Whisperæ¨¡å‹å·²ç¼“å­˜"
    else
        print_warning "Whisperæ¨¡å‹æœªæ‰¾åˆ°ï¼Œé¦–æ¬¡è¿è¡Œæ—¶å°†è‡ªåŠ¨ä¸‹è½½"
    fi
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    if [[ ! -d "./data" ]]; then
        mkdir -p ./data/audio_files ./data/analysis_results
        print_status "åˆ›å»ºæ•°æ®ç›®å½•"
    fi
}

# ç³»ç»Ÿä¼˜åŒ–
optimize_system() {
    print_progress "åº”ç”¨ç³»ç»Ÿä¼˜åŒ–..."
    
    # è®¾ç½®HuggingFaceé•œåƒ
    export HF_ENDPOINT="https://hf-mirror.com"
    print_status "è®¾ç½®HuggingFaceé•œåƒæº"
    
    # è®¾ç½®PyTorchä¼˜åŒ–
    export OMP_NUM_THREADS=$(nproc)
    export MKL_NUM_THREADS=$(nproc)
    print_status "è®¾ç½®å¤šçº¿ç¨‹ä¼˜åŒ–"
    
    # GPUå†…å­˜ä¼˜åŒ–
    export CUDA_VISIBLE_DEVICES="0"
    print_status "è®¾ç½®GPUè®¾å¤‡"
    
    print_status "ç³»ç»Ÿä¼˜åŒ–å®Œæˆ"
}

# å¯åŠ¨æœåŠ¡
start_service() {
    print_progress "å¯åŠ¨AIè¯­éŸ³æ”¿æ²»é£é™©ç›‘æ§ç³»ç»Ÿ..."
    
    # æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
    PORT=8000
    if lsof -i:$PORT &> /dev/null; then
        print_warning "ç«¯å£ $PORT å·²è¢«å ç”¨ï¼Œå°è¯•ç»ˆæ­¢ç°æœ‰è¿›ç¨‹..."
        pkill -f "uvicorn.*main_new:app" || true
        sleep 2
    fi
    
    # å¯åŠ¨FastAPIæœåŠ¡
    print_status "åœ¨ç«¯å£ $PORT å¯åŠ¨æœåŠ¡..."
    echo -e "${CYAN}"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo "ğŸŒ æœåŠ¡åœ°å€: http://localhost:$PORT"
    echo "ğŸ“š APIæ–‡æ¡£: http://localhost:$PORT/docs"
    echo "ğŸ”§ å¥åº·æ£€æŸ¥: http://localhost:$PORT/health"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo -e "${NC}"
    
    # å¯åŠ¨æœåŠ¡
    cd "$(dirname "$0")"
    
    if [[ -f "app/main_new.py" ]]; then
        uvicorn app.main_new:app --host 0.0.0.0 --port $PORT --reload
    elif [[ -f "main.py" ]]; then
        uvicorn main:app --host 0.0.0.0 --port $PORT --reload
    else
        print_error "æœªæ‰¾åˆ°ä¸»åº”ç”¨æ–‡ä»¶ (app/main_new.py æˆ– main.py)"
    fi
}

# å®‰è£…ä¾èµ–
install_dependencies() {
    print_progress "å®‰è£…Pythonä¾èµ–..."
    
    if [[ -f "requirements.txt" ]]; then
        pip install -r requirements.txt
        print_status "ä¾èµ–å®‰è£…å®Œæˆ"
    else
        print_error "requirements.txtæ–‡ä»¶æœªæ‰¾åˆ°"
    fi
}

# ä¸»å‡½æ•°
main() {
    # åˆ‡æ¢åˆ°è„šæœ¬ç›®å½•
    cd "$(dirname "$0")"
    
    # å®‰è£…ä¾èµ–ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if [[ "$1" == "--install" ]] || [[ "$1" == "-i" ]]; then
        install_dependencies
    fi
    
    # ç¯å¢ƒæ£€æŸ¥
    check_python_env
    check_dependencies
    check_gpu
    
    # æ¨¡å‹æ£€æŸ¥
    check_models
    
    # ç³»ç»Ÿä¼˜åŒ–
    optimize_system
    
    # å¯åŠ¨æœåŠ¡
    start_service
}

# æ˜¾ç¤ºå¸®åŠ©
show_help() {
    echo -e "${YELLOW}ç”¨æ³•:${NC}"
    echo "  ./start.sh              # å¯åŠ¨ç³»ç»Ÿ"
    echo "  ./start.sh --install    # å®‰è£…ä¾èµ–å¹¶å¯åŠ¨"
    echo "  ./start.sh --help       # æ˜¾ç¤ºå¸®åŠ©"
    echo ""
    echo -e "${YELLOW}é€‰é¡¹:${NC}"
    echo "  -i, --install     å®‰è£…ä¾èµ–åŒ…"
    echo "  -h, --help        æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"
    echo ""
    echo -e "${YELLOW}ç³»ç»Ÿè¦æ±‚:${NC}"
    echo "  â€¢ Python 3.8+"
    echo "  â€¢ PyTorch with CUDA"
    echo "  â€¢ è‡³å°‘8GB GPUæ˜¾å­˜ï¼ˆæ¨è16GB+ï¼‰"
    echo "  â€¢ 16GB+ ç³»ç»Ÿå†…å­˜"
}

# ä¼˜é›…é€€å‡ºå¤„ç†
cleanup() {
    echo -e "\n${YELLOW}æ­£åœ¨å…³é—­æœåŠ¡...${NC}"
    pkill -f "uvicorn.*main_new:app" || true
    print_status "æœåŠ¡å·²å…³é—­"
    exit 0
}

trap cleanup SIGINT SIGTERM

# å‚æ•°å¤„ç†
case "${1:-}" in
    -h|--help)
        show_help
        exit 0
        ;;
    *)
        main "$@"
        ;;
esac
